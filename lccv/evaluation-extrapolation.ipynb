{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for Extrapolating the Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "results_file = os.path.expanduser('data/extrapolation.csv')\n",
    "df = pd.read_csv(results_file)\n",
    "\n",
    "classifiers = df['classifier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_cor, axes_cor  = plt.subplots(1, 2, figsize=(12,4), gridspec_kw={'hspace': 0.4})\n",
    "fig_acc, axes_acc  = plt.subplots(2, 2, figsize=(12,6), gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "\n",
    "for classifier in [\"LinearSVC()\", \"GradientBoostingClassifier()\", \"LinearDiscriminantAnalysis()\", \"QuadraticDiscriminantAnalysis()\", \"RandomForestClassifier()\"]:\n",
    "    fig_ind, (ax1, ax2, ax3)  = plt.subplots(1, 3, figsize=(16,4))\n",
    "    \n",
    "    result_clf = df.loc[df['classifier'] == classifier]\n",
    "    \n",
    "    # for regression acc plot\n",
    "    perf = np.abs(result_clf['performance_next_point'] - result_clf['performance_prediction']).values\n",
    "    count, bins_count = np.histogram(perf, bins=1000)\n",
    "    pdf = count / sum(count)\n",
    "    cdf = np.cumsum(pdf)\n",
    "    \n",
    "    # for curve plot\n",
    "    curve_plot_x = np.arange(0, 1, 0.01)\n",
    "    curve_plot_y = []\n",
    "    for i in curve_plot_x:\n",
    "        cur_val = ((result_clf['delta_current_actual'] < i) & (result_clf['delta_current_prediction'].values < i)) | ((result_clf['delta_current_actual'].values >= i) & (result_clf['delta_current_prediction'].values >= i))\n",
    "        curve_plot_y.append(sum(cur_val) / len(cur_val))\n",
    "    \n",
    "    # build upon individual plots\n",
    "    fig_ind.suptitle(classifier)\n",
    "    ax1.scatter(result_clf['delta_current_actual'], result_clf['delta_current_prediction'])\n",
    "    ax2.plot(bins_count[1:], cdf)\n",
    "    ax3.plot(curve_plot_x, curve_plot_y)\n",
    "    ax3.set_ylim([0,1.05])\n",
    "    ax3.axhline(0.9, linestyle=\"--\", linewidth=1, color=\"black\")\n",
    "    \n",
    "    # adds to general plot\n",
    "    axes_cor[0].scatter(result_clf['delta_current_prediction'], result_clf['delta_current_actual'], s=3)\n",
    "    axes_cor[0].set_title(\"Actual vs. predicted improvements per learner\")\n",
    "    axes_acc[0][0].plot(bins_count[1:], cdf, label=classifier[:-2])\n",
    "    axes_acc[0][0].set_title(\"Correct classifications by tolerance per learner\")\n",
    "    axes_acc[1][0].plot(curve_plot_x, curve_plot_y)\n",
    "    axes_acc[1][0].set_title(\"Correct classifications by threshold per learner\")\n",
    "\n",
    "### now for the portfolio selection (based on FULL portfolio)\n",
    "best_actual = []\n",
    "best_predicted = []\n",
    "for dataset, df_dataset in df.groupby(\"task_id\"):\n",
    "    # best performing classifier at halfway point (lower is better)\n",
    "    best_score_on_half = min(df_dataset[\"performance_curve_end\"])\n",
    "    # best performing classifier at full point (lower is better)\n",
    "    best_score_on_full = min(df_dataset['performance_next_point'])\n",
    "    # delta of the best obtained score at full point minus halfway point (higher is better!)\n",
    "    delta_best = best_score_on_half - best_score_on_full\n",
    "    # per-classifier prediction how much it will improve over the best classifier so far (higher is better)\n",
    "    df_dataset['delta_currentbest_prediction'] = best_score_on_half - df_dataset[\"performance_prediction\"]\n",
    "    # the best predicted performance gain (maximize)\n",
    "    best_predicted_delta = max(df_dataset[\"delta_currentbest_prediction\"])\n",
    "    \n",
    "    best_actual.append(delta_best)\n",
    "    best_predicted.append(best_predicted_delta)\n",
    "best_actual = np.array(best_actual)\n",
    "best_predicted = np.array(best_predicted)\n",
    "\n",
    "# for regression acc plot\n",
    "perf = np.abs(best_actual - best_predicted)\n",
    "count, bins_count = np.histogram(perf, bins=1000)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "\n",
    "# for curve plot\n",
    "curve_plot_x = np.arange(0, 1, 0.01)\n",
    "curve_plot_y = []\n",
    "for i in curve_plot_x:\n",
    "    cur_val = ((best_actual < i) & (best_predicted < i)) | ((best_actual >= i) & (best_predicted >= i))\n",
    "    curve_plot_y.append(sum(cur_val) / len(cur_val)) \n",
    "\n",
    "portfolio_color = \"C5\"\n",
    "axes_cor[1].scatter(best_predicted, best_actual, s=8, color=portfolio_color)\n",
    "axes_cor[1].set_title(\"Actual vs. predicted improvements for portfolio\")\n",
    "axes_acc[0][1].plot(bins_count[1:], cdf, color=portfolio_color, label=\"Portfolio\")\n",
    "axes_acc[0][1].set_title(\"Correct classifications by tolerance for portfolio\")\n",
    "axes_acc[1][1].plot(curve_plot_x, curve_plot_y, color=portfolio_color)\n",
    "axes_acc[1][1].set_title(\"Correct classifications by threshold for portfolio\")\n",
    "    \n",
    "for col in range(2):\n",
    "    axes_cor[col].set_xlim([-0.2, 0.6])\n",
    "    axes_cor[col].set_ylim([-0.2, 0.6])\n",
    "    axes_cor[col].plot([-0.2, 1], [-0.2, 1], linestyle=\"--\", linewidth=1, color=\"black\")\n",
    "    \n",
    "    axes_acc[1][col].set_xlim([0, 0.34])\n",
    "    axes_acc[1][col].set_ylim([0.5,1.05])\n",
    "    \n",
    "    axes_cor[col].set_xlabel(\"Predicted Improvement\")\n",
    "    axes_cor[col].set_ylabel(\"Actual Improvement\")\n",
    "    axes_acc[0][col].set_xlabel(\"Tolerated Deviation for Correct Prediction\")\n",
    "    axes_acc[0][col].axhline(0.9, linestyle=\"--\", linewidth=1, color=\"black\")\n",
    "    axes_acc[0][col].set_ylabel(\"Accuracy\")\n",
    "    axes_acc[1][col].set_xlabel(\"Required Improvement\")\n",
    "    axes_acc[1][col].set_ylabel(\"Accuracy\")\n",
    "    axes_acc[1][col].axhline(0.95, linestyle=\"--\", linewidth=1, color=\"black\")\n",
    "\n",
    "handles, labels = axes_cor[0].get_legend_handles_labels()\n",
    "handles_port, labels_port = axes_cor[1].get_legend_handles_labels()\n",
    "handles.extend(handles_port)\n",
    "labels.extend(labels_port)\n",
    "lgd = fig_cor.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.45, 0.06), ncol=3)\n",
    "#fig.tight_layout()\n",
    "fig_cor.savefig(\"plots/results-correlation.pdf\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "fig_acc.savefig(\"plots/results-accuracy.pdf\", bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "plt.show()\n",
    "# print('results on %d tasks:' % len(result_clf['task_id']), result_clf['task_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
