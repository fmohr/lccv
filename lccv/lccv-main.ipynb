{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from os import path\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn import *\n",
    "\n",
    "\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools as it\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset(openmlid):\n",
    "    ds = openml.datasets.get_dataset(openmlid)\n",
    "    df = ds.get_data()[0].dropna()\n",
    "    y = df[ds.default_target_attribute].values\n",
    "    \n",
    "    categorical_attributes = df.select_dtypes(exclude=['number']).columns\n",
    "    expansion_size = 1\n",
    "    for att in categorical_attributes:\n",
    "        expansion_size *= len(pd.unique(df[att]))\n",
    "        if expansion_size > 10**5:\n",
    "            break\n",
    "    \n",
    "    if expansion_size < 10**5:\n",
    "        X = pd.get_dummies(df[[c for c in df.columns if c != ds.default_target_attribute]]).values.astype(float)\n",
    "    else:\n",
    "        print(\"creating SPARSE data\")\n",
    "        dfSparse = pd.get_dummies(df[[c for c in df.columns if c != ds.default_target_attribute]], sparse=True)\n",
    "        \n",
    "        print(\"dummies created, now creating sparse matrix\")\n",
    "        X = lil_matrix(dfSparse.shape, dtype=np.float32)\n",
    "        for i, col in enumerate(dfSparse.columns):\n",
    "            ix = dfSparse[col] != 0\n",
    "            X[np.where(ix), i] = 1\n",
    "        print(\"Done. shape is\" + str(X.shape))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(learner, X, y, train_size, repeats):\n",
    "    scores = []\n",
    "    n = X.shape[0]\n",
    "    num_examples = int(train_size * n)\n",
    "    \n",
    "    for r in range(repeats):\n",
    "        indices_train = random.sample(range(n), num_examples)\n",
    "        learner.fit(X[indices_train,:], y[indices_train])\n",
    "        indices_test = [i for i in range(n) if not i in indices_train]\n",
    "        \n",
    "        # compute validation error\n",
    "        y_hat = learner.predict(X[indices_test])\n",
    "        mistakes = 0\n",
    "        for i, pred in enumerate(y_hat):\n",
    "            act = y[indices_test[i]]\n",
    "            if pred != act:\n",
    "                mistakes += 1\n",
    "        scores.append(mistakes / len(indices_test))\n",
    "        \n",
    "    return np.mean(scores)\n",
    "\n",
    "def plot_learning_curves(learners, X, y, ax = None, train_portions = [0.05, 0.1, 0.2, 0.5, 0.7], repeats=10):\n",
    "    total = len(learners) * len(train_portions)\n",
    "    pbar = tqdm(total=total)\n",
    "    for j, learner in enumerate(learners):\n",
    "        scores_val = []\n",
    "        slopes = []\n",
    "        for i, train_portion in enumerate(train_portions):\n",
    "            e_out = cross_validate(learner, X, y, train_portion, repeats)\n",
    "            scores_val.append(e_out)\n",
    "            if i > 0:\n",
    "                slope = (e_out - scores_val[-2]) / (train_portion - train_portions[i-1])\n",
    "                slopes.append(slope)\n",
    "        \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        x_axis = np.round(X.shape[0] * np.array(train_portions)).astype(int)\n",
    "        ax.plot(x_axis, scores_val, label=learner.__class__, color=\"C\" + str(j))\n",
    "        for i, train_portion in enumerate(train_portions):\n",
    "            if i > 1 and slopes[i-1] < max(slopes[:i-1]):\n",
    "                x = np.round(X.shape[0] * np.array([train_portions[i-1], train_portion])).astype(int)\n",
    "                ax.fill_between(x, [0, 0], [scores_val[i-1], scores_val[i]], color=\"C\" + str(j), alpha=0.2)\n",
    "                \n",
    "            pbar.update(1)\n",
    "        ax.set_ylim([0,1])\n",
    "    pbar.close()\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def gather_learning_curve_results(learners, datasets, train_portions, seeds):\n",
    "    \n",
    "    # read in data frame if exists\n",
    "    FILENAME = \"data/learningcurves.csv\"\n",
    "    cols = [\"openmlid\", \"learner\", \"train_size\", \"seed\", \"error_rate\"]\n",
    "    df = pd.read_csv(FILENAME) if path.exists(FILENAME) else pd.DataFrame([], columns=cols)\n",
    "    \n",
    "    total = len(datasets) * len(learners) * len(train_portions) * len(seeds)\n",
    "    pbar = tqdm(total=total)\n",
    "    rows = []\n",
    "    unsaved_changes = 0\n",
    "    interrupted = False\n",
    "    for openmlid in datasets:\n",
    "        dsIndex = df[\"openmlid\"] == openmlid\n",
    "        \n",
    "        print(\"DATASET\", openmlid)\n",
    "        X, y = getDataset(openmlid)\n",
    "        n = X.shape[0]\n",
    "        if n == 0:\n",
    "            print(\"Omit empty dataset!\")\n",
    "        \n",
    "        if interrupted:\n",
    "            break\n",
    "        \n",
    "        for seed in seeds:\n",
    "            if interrupted:\n",
    "                break\n",
    "            dsSeed = dsIndex & (df[\"seed\"] == seed)\n",
    "            for j, learner in enumerate(learners):\n",
    "                if interrupted:\n",
    "                    break\n",
    "                dsLearner = dsSeed & (df[\"learner\"] == str(learner))\n",
    "                scores_val = []\n",
    "                slopes = []\n",
    "                for i, train_portion in enumerate(train_portions):\n",
    "                    if interrupted:\n",
    "                        break\n",
    "                    random.seed(seed)\n",
    "                    num_examples = train_portion if type(train_portion) == int else int(train_portion * n)\n",
    "                    if n - num_examples < 100:\n",
    "                        print(\"Dataset has only \" + str(n) +\" instances in total. That is not enough samples to train on \" + str(num_examples) + \". Skipping\")\n",
    "                    else:\n",
    "                        dsPortion = dsLearner & (df[\"train_size\"] == num_examples)\n",
    "                        if np.count_nonzero(dsPortion) == 0:\n",
    "                            try:\n",
    "                                indices_train = random.sample(range(n), num_examples)\n",
    "                                indices_test = [i for i in range(n) if not i in indices_train]\n",
    "                                indices_test = indices_test[:10000] # maximum 10k validation instances\n",
    "                                X_train = X[indices_train]\n",
    "                                y_train = y[indices_train]\n",
    "                                X_test = X[indices_test]\n",
    "                                y_test = y[indices_test]\n",
    "\n",
    "                                inst = learner()\n",
    "                                print(\"Training \" + str(learner) + \" on data of shape \" + str(X_train.shape))\n",
    "                                inst.fit(X_train, y_train)\n",
    "                                print(\"Training ready. Obtaining predictions for \" + str(X_test.shape[0]) + \" instances.\")\n",
    "                                y_hat = inst.predict(X_test)\n",
    "                                error_rate = 1 - sklearn.metrics.accuracy_score(y_test, y_hat)\n",
    "                                row = [openmlid, str(learner), num_examples, seed, error_rate]\n",
    "                                df.loc[len(df)] = row\n",
    "                                unsaved_changes += 1\n",
    "\n",
    "                                print(unsaved_changes, \"unsaved changes\")\n",
    "                                if unsaved_changes >= 100:\n",
    "                                    df.to_csv(FILENAME, index=False)\n",
    "                                    unsaved_changes = 0\n",
    "                            except KeyboardInterrupt:\n",
    "                                print(\"Interrupted\")\n",
    "                                interrupted = True\n",
    "                                break\n",
    "                            except:\n",
    "                                print(\"An error occurred on \" + str(openmlid) + \" with learner \" + str(learner) + \" under seed \" + str(seed) + \" for \" + str(num_examples) + \" examples.\")\n",
    "                    pbar.update(1)\n",
    "    pbar.close()\n",
    "    if unsaved_changes > 0:\n",
    "        df.to_csv(FILENAME, index=False)\n",
    "        unsaved_changes = 0\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dense = [1485, 1515, 1475, 1468, 1489, 23512, 23517, 40981, 40982, 40983, 40984, 40701, 40685, 40900,  1111, 40498, 41161, 41162, 41163, 41164, 41165, 41166, 41167, 41168, 41169, 41142, 41143, 41144, 41145, 41146, 41150, 41156, 41157, 41158,  41159, 41138, 54, 181, 188, 1461, 1494, 1464, 12, 23, 3, 1487, 40668, 1067, 1049, 40975, 31]\n",
    "#1457\n",
    "datasets_sparse = [1590, 1486, 4534, 4541, 4538, 4134, 4135, 40978, 40996, 41027, 40670, 42732, 42733, 42734, 41147]\n",
    "datasets = datasets_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learners = [\n",
    "    (sklearn.svm.LinearSVC, {}),\n",
    "    (sklearn.tree.DecisionTreeClassifier, {}),\n",
    "    (sklearn.tree.ExtraTreeClassifier, {}),\n",
    "    (sklearn.linear_model.LogisticRegression, {}),\n",
    "    (sklearn.linear_model.PassiveAggressiveClassifier, {}),\n",
    "    (sklearn.linear_model.Perceptron, {}),\n",
    "    (sklearn.linear_model.RidgeClassifier, {}),\n",
    "    (sklearn.linear_model.SGDClassifier, {}),\n",
    "    (sklearn.neural_network.MLPClassifier, {}),\n",
    "    (sklearn.discriminant_analysis.LinearDiscriminantAnalysis, {}),\n",
    "    (sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis, {}),\n",
    "    (sklearn.naive_bayes.BernoulliNB, {}),\n",
    "    (sklearn.naive_bayes.MultinomialNB, {}),\n",
    "    (sklearn.neighbors.KNeighborsClassifier, {}),\n",
    "    (sklearn.ensemble.ExtraTreesClassifier, {}),\n",
    "    (sklearn.ensemble.RandomForestClassifier, {}),\n",
    "    (sklearn.ensemble.GradientBoostingClassifier, {})\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%disabled\n",
    "#gather_learning_curve_results([l[0] for l in learners], datasets, [0.05, 0.1, 0.2, 0.5], range(10))\n",
    "L = [sklearn.neighbors._classification.KNeighborsClassifier]\n",
    "dfLC = gather_learning_curve_results(L, datasets, [100, 200, 400, 800, 1600, 3200], range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(observations, n, stats=lambda x: np.mean(x)):\n",
    "    if len(observations) <= 2:\n",
    "        raise Exception(\"Cannot compute bootstrap sample of less than 2 observations!\")\n",
    "    bootstraps = []\n",
    "    observations_as_list = list(observations)\n",
    "    bootstrap_size = int(0.5 * len(observations_as_list))\n",
    "    for i in range(n):\n",
    "        sub_sample = random.sample(observations_as_list, bootstrap_size)\n",
    "        bootstraps.append(stats(sub_sample))\n",
    "    return bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import time\n",
    "\n",
    "def evaluate(learner, X, y, num_examples, seed=0):\n",
    "    random.seed(seed)\n",
    "    n = X.shape[0]\n",
    "    indices_train = random.sample(range(n), num_examples)\n",
    "    mask_train = np.zeros(n)\n",
    "    mask_train[indices_train] = 1\n",
    "    mask_train = mask_train.astype(bool)\n",
    "    mask_test = (1 - mask_train).astype(bool)\n",
    "    X_train = X[mask_train]\n",
    "    y_train = y[mask_train]\n",
    "    X_test = X[mask_test][:10000]\n",
    "    y_test = y[mask_test][:10000]\n",
    "\n",
    "    inst = learner()\n",
    "    #print(\"Training \" + str(learner) + \" on data of shape \" + str(X_train.shape))\n",
    "    inst.fit(X_train, y_train)\n",
    "    #print(\"Training ready. Obtaining predictions for \" + str(X_test.shape[0]) + \" instances.\")\n",
    "    y_hat = inst.predict(X_test)\n",
    "    return 1 - sklearn.metrics.accuracy_score(y_test, y_hat)\n",
    "\n",
    "def getSlopes(anchor_points, observations):\n",
    "    slopes = []\n",
    "    for i, o in enumerate(observations):\n",
    "        if i > 0:\n",
    "            slope = (mean(o) - mean(observations[i-1])) / (anchor_points[i] - anchor_points[i-1])\n",
    "            slopes.append(slope)\n",
    "    return slopes\n",
    "\n",
    "def mean(A):\n",
    "    if len(A) == 0:\n",
    "        raise Exception(\"Cannot compute mean for empty set.\")\n",
    "    #return scipy.stats.trim_mean(A, 0.1)\n",
    "    return np.mean(A)\n",
    "\n",
    "def getLCApproximation(sizes, scores):\n",
    "    def ipl(beta):\n",
    "        a, b, c = tuple(beta.astype(float))\n",
    "        pl = lambda x: a + b * x **(-c)\n",
    "        penalty = []\n",
    "        for i, size in enumerate(sizes):\n",
    "            penalty.append((pl(size) - scores[i])**2)\n",
    "        return np.array(penalty)\n",
    "\n",
    "    a, b, c = tuple(scipy.optimize.least_squares(ipl, np.array([1,1,1]), method=\"lm\").x)\n",
    "    return lambda x: a + b * x **(-c)\n",
    "\n",
    "\n",
    "def getStagesAndBudgets(n, k = 10, alpha = .5, gamma = 2, min_anchor_points = 5):\n",
    "        \n",
    "    # derive basic sizes\n",
    "    d = int(np.floor(np.log(.9 * n) / np.log(2)))\n",
    "    ac = alpha * k\n",
    "    \n",
    "    # optimize for c and beta\n",
    "    c = min_anchor_points + 1\n",
    "    beta = (alpha / gamma)**(1/(c-min_anchor_points))\n",
    "    while np.sum([1/(2*beta)**i for i in range(c - min_anchor_points + 1)]) <= 2**(d-c)/alpha:\n",
    "        c += 1\n",
    "        beta = (alpha / gamma)**(1/(c-min_anchor_points))\n",
    "    c -= 1\n",
    "    beta = (alpha / gamma)**(1/(c-min_anchor_points))\n",
    "    \n",
    "    # define anchor points and time budgets\n",
    "    points = 2**np.array(range(min_anchor_points, c + 1))\n",
    "    budgets = []\n",
    "    for i, p in enumerate(points):\n",
    "        budgets.append(int(np.round(ac / (beta**(c-i - min_anchor_points)))))\n",
    "    return c, budgets\n",
    "\n",
    "\n",
    "def LCCV(learner, X, y, target_size=None, r = 0.0, min_stages = 3, timeout=60, enforce_lc_construction=False):\n",
    "    \n",
    "    deadline = time.time() + timeout\n",
    "    print(\"Running LCCV with timeout\",timeout)\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    min_exp = 6\n",
    "    \n",
    "    \n",
    "    if target_size is None:\n",
    "        target_size = 0.9 * n\n",
    "        print(\"Setting target size to \" + str(target_size) + \" as 90% of the original dataset.\")\n",
    "    \n",
    "    # compute budgets and phases\n",
    "    max_exp, repeats = getStagesAndBudgets(X.shape[0], gamma=2)\n",
    "    print(min_exp, max_exp, repeats)\n",
    "    anchors = list(range(min_exp, max_exp + 1))\n",
    "    \n",
    "    # start LCCV algorithm\n",
    "    \n",
    "    observations = []\n",
    "    mean_observations = []\n",
    "    \n",
    "    for stage_id, exp in enumerate(tqdm(anchors)):\n",
    "        if time.time() > deadline:\n",
    "            break\n",
    "        num_examples = 2**exp\n",
    "        num_evaluations = repeats[stage_id]\n",
    "        print (\"Running stage for \" + str(num_examples) + \" examples. At most \" + str(num_evaluations) + \" evaluations will be allowed.\")\n",
    "        \n",
    "        stabilized = False\n",
    "        \n",
    "        observations_at_anchor = []\n",
    "        variances = []\n",
    "        \n",
    "        base_evaluations = 0\n",
    "        while not stabilized and base_evaluations < num_evaluations and time.time() < deadline:\n",
    "            observations_at_anchor.append(evaluate(learner, X, y, num_examples))\n",
    "            \n",
    "            # criterion 1: low variance in mean estimation\n",
    "            if len(observations_at_anchor) > 2:\n",
    "                bootstrap_samples = get_bootstrap_samples(observations_at_anchor, n = 100)\n",
    "                variances.append(np.var(bootstrap_samples))\n",
    "                stabilized = variances[-1] < 0.00001\n",
    "            base_evaluations += 1\n",
    "        \n",
    "        observations.append(observations_at_anchor)\n",
    "        mean_observations.append(mean(observations_at_anchor))\n",
    "        print(\"Obtained low-variance result for stage \" + str(exp))\n",
    "        \n",
    "        # \"repair\" curve until convex\n",
    "        print(len(mean_observations))\n",
    "        expected = np.array(range(len(mean_observations)))\n",
    "        mismatches = (-np.array(mean_observations)).argsort() != expected\n",
    "        reevaluations = 0\n",
    "        while np.count_nonzero(mismatches) and len(observations[stage_id]) < repeats[stage_id] and time.time() < deadline:\n",
    "            reevaluate = np.where(mismatches)[0]\n",
    "            print(\"Found mismatches.\", (-np.array(mean_observations)).argsort(), expected, mismatches, \"Re-Evaluating\", reevaluate)\n",
    "            any_adjusted = False\n",
    "            for i in reevaluate:\n",
    "                if len(observations[i]) < repeats[i]:\n",
    "                    print(\"Re-Evaluting\", 2**anchors[i])\n",
    "                    new_score = evaluate(learner, X, y, 2**anchors[i])\n",
    "                    observations[i].append(new_score)\n",
    "                    mean_prev = mean_observations[i]\n",
    "                    mean_observations[i] = mean(observations[i])\n",
    "                    print(\"Updated mean\", mean_observations[i], \"previously was\",mean_prev)\n",
    "                    any_adjusted = True\n",
    "            if not any_adjusted:\n",
    "                break\n",
    "            sorted_anchor_indices = (-np.array(mean_observations)).argsort()\n",
    "            print(sorted_anchor_indices, mean_observations)\n",
    "            mismatches = sorted_anchor_indices != expected\n",
    "            reevaluations += 1\n",
    "        \n",
    "        \n",
    "        slopes = getSlopes([2**e for e in anchors], observations)\n",
    "        print(\"slopes:\", slopes)\n",
    "        faulty_segments = [i for i, s in enumerate(slopes) if i > 0 and s < slopes[i-1]]\n",
    "        while len(faulty_segments) > 0 and base_evaluations < num_evaluations and time.time() < deadline:\n",
    "            reevaluate = []\n",
    "            for i in faulty_segments:\n",
    "                reevaluate = reevaluate + [i-1, i, i+1]\n",
    "            reevaluate = list(np.unique(reevaluate))\n",
    "            for i in reevaluate:\n",
    "                if len(observations[i]) < repeats[i] and time.time() < deadline:\n",
    "                    print(\"Re-Evaluting\", 2**anchors[i])\n",
    "                    new_score = evaluate(learner, X, y, 2**anchors[i])\n",
    "                    observations[i].append(new_score)\n",
    "                    mean_prev = mean_observations[i]\n",
    "                    mean_observations[i] = mean(observations[i])\n",
    "                    print(\"Updated mean\", mean_observations[i], \"previously was\",mean_prev)\n",
    "            slopes = getSlopes([2**e for e in anchors], observations)\n",
    "            print(\"slopes:\", slopes)\n",
    "            faulty_segments = [i for i, s in enumerate(slopes) if i > 0 and s < slopes[i-1]]\n",
    "            base_evaluations += 1\n",
    "        \n",
    "        #for i, obs in enumerate(slopes):\n",
    "        \n",
    "        if len(faulty_segments) == 0:\n",
    "            print(\"Obtained stable result for stage \" + str(exp))\n",
    "        else:\n",
    "            print(\"Stopped stage \" + str(exp) + \" with unstable result.\")\n",
    "#        plt.plot(variances)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # get projections\n",
    "        if len(slopes) > 0 and stage_id + 1 >= min_stages:\n",
    "            \n",
    "            ## convex bound\n",
    "            last_negative_slope_index = len(slopes) - 1\n",
    "            while slopes[last_negative_slope_index] > 0:\n",
    "                last_negative_slope_index -= 1\n",
    "            slope = slopes[last_negative_slope_index]\n",
    "            projected_score = mean_observations[stage_id] + (target_size - num_examples) * slope\n",
    "            print(\"Projected score for target size \" + str(target_size) + \" (from anchor \" + str(num_examples) + \" with mean \" + str(mean_observations[stage_id]) + \" and slope \" + str(slope) + \"):\", projected_score)\n",
    "            if projected_score > r:\n",
    "                print(\"Impossibly competitive, stopping execution.\")\n",
    "                return np.mean(observations[-1]), anchors, observations\n",
    "        \n",
    "            ## inverse power law approximation\n",
    "            indices = [i for i, exp in enumerate(anchors[:len(mean_observations)]) if exp >= 3][-4:]\n",
    "            if len(indices) >= 3:\n",
    "                sizes = np.array([2**e for e in anchors])[indices]\n",
    "                scores =  np.array(mean_observations)[indices]\n",
    "                pl_approx = getLCApproximation(sizes, scores)\n",
    "                #fig, ax = plt.subplots()\n",
    "                #ax.plot(sizes, scores)\n",
    "                #domain = np.linspace(0, 10000, 100)\n",
    "                #ax.plot(domain, pl_approx(domain))\n",
    "                #plt.show()\n",
    "    return np.mean(observations[-1]), anchors, observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _DISABLED_fitAndPredict(learner_inst, X_train, y_train, X_test, y_test):\n",
    "    print(\"Fitting with \" + str(X_train.shape[0]) + \" instances.\")\n",
    "    learner_inst.fit(X_train, y_train)\n",
    "    # compute validation error\n",
    "    y_hat = learner_inst.predict(X_test)\n",
    "    mistakes = 0\n",
    "    print(\"Testing on \" + str(y_hat.shape[0]) + \" instances.\")\n",
    "    for i, pred in enumerate(y_hat):\n",
    "        act = y_test[i]\n",
    "        if pred != act:\n",
    "            mistakes += 1            # compute validation error\n",
    "    return mistakes / X_test.shape[0]\n",
    "            \n",
    "            \n",
    "def cv10(learner, X, y, target_size=None, r = 0.0, min_stages = 3, timeout=60, seed=0):\n",
    "\n",
    "    train_size = 0.9\n",
    "    repeats = 10\n",
    "    deadline = time.time() + timeout\n",
    "    \n",
    "    scores = []\n",
    "    n = X.shape[0]\n",
    "    num_examples = int(train_size * n)\n",
    "    \n",
    "    print(\"running 10cv for \" + str(timeout))\n",
    "    \n",
    "    for r in range(repeats):\n",
    "        print(\"Repeat\", r+1)\n",
    "        try:\n",
    "            if deadline <= time.time():\n",
    "                break\n",
    "            scores.append(func_timeout(deadline - time.time(), evaluate, (learner, X, y, num_examples, seed+1)))\n",
    "        except FunctionTimedOut:\n",
    "            print(\"TIMED OUT\")\n",
    "            break\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"interrupted\")\n",
    "            break\n",
    "    \n",
    "    return np.mean(scores) if len(scores) > 0 else np.nan, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(validation, learners, X, y, timeout_per_evaluation, epsilon):\n",
    "    validation_func = validation[0]\n",
    "    validation_result_extractor = validation[1]\n",
    "    \n",
    "    hard_cutoff = 2 * timeout_per_evaluation\n",
    "    r = 1.0\n",
    "    best_score = 1\n",
    "    chosen_learner = None\n",
    "    validation_times = []\n",
    "    for learner in tqdm(learners):\n",
    "        print(\"Checking learner \" + str(learner))\n",
    "        try:\n",
    "            validation_start = time.time()\n",
    "            score = validation_result_extractor(validation_func(learner, X, y, r = r, timeout=timeout_per_evaluation))\n",
    "            validation_times.append(time.time() - validation_start)\n",
    "            print(\"Observed score \" + str(score) + \" for \" + str(learner))\n",
    "            r = min(r, score + epsilon)\n",
    "            print(\"r is now:\", r)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                chosen_learner = learner\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted, stopping\")\n",
    "            break\n",
    "        except:\n",
    "            print(\"Could NOT evaluate \" + str(learner))\n",
    "    \n",
    "    return chosen_learner, validation_times\n",
    "\n",
    "def evaluate_validator(validation, learners, X, y, timeout_per_evaluation, epsilon):\n",
    "    chosen_learner = select_model(validation, learners, X, y, timeout_per_evaluation, epsilon)\n",
    "    print(\"Chosen learner is \" + str(chosen_learner) + \". Now computing its definitive performance.\")\n",
    "    true_performance = cv10(chosen_learner, X, y, timeout=60*60*24, seed=0)\n",
    "    return true_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openmlid = 23512\n",
    "openmlid = 31\n",
    "X, y = getDataset(openmlid)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_model((LCCV, lambda r: r[0]), [l[0] for l in learners], X, y, 60, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_model((cv10, lambda r: r[0]), [l[0] for l in learners], X, y, 60, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_learners = [l[0] for l in learners]\n",
    "test_learners.reverse()\n",
    "print(test_learners)\n",
    "for openmlid in tqdm(datasets_dense):\n",
    "    print(openmlid)\n",
    "    X, y = getDataset(openmlid)\n",
    "    for validator in [cv10, LCCV]:\n",
    "        print(\"-------------------------------\\n\" + validator.__name__ + \"\\n-------------------------------\")\n",
    "        time_start = time.time()\n",
    "        score, observations = evaluate_validator((validator, lambda r: r[0]), test_learners, X, y, 60, 0.0)\n",
    "        runtime = int(np.round(time.time() - time_start))\n",
    "        print(\"Runtime was \" + str(runtime) + \"s. Performance was \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#evaluate(sklearn.neighbors.KNeighborsClassifier, X, y, int(0.9 * X.shape[0]))\n",
    "evaluate(sklearn.tree.ExtraTreeClassifier, X, y, int(0.9 * X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = []\n",
    "scores = []\n",
    "for i, anchor in enumerate(a):\n",
    "    if i >= len(o):\n",
    "        break\n",
    "    sizes.append(2**anchor)\n",
    "    mean = np.mean(o[i])\n",
    "    print(len(o[i]), mean)\n",
    "    scores.append(mean)\n",
    "print(np.argsort([np.mean(ol) for ol in o]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(sizes, scores)\n",
    "#ax.set_ylim([0,1])\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(o)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indices = np.array(sizes) > 200\n",
    "pl = getLCApproximation(np.array(sizes)[indices], np.array(scores)[indices])\n",
    "\n",
    "domain = np.linspace(0, 10000, 100)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(domain, pl(domain))\n",
    "ax.plot(sizes, scores)\n",
    "#ax.set_ylim([0.45, 0.48])\n",
    "\n",
    "#ipl(np.array([0.5, 0.2, 3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
