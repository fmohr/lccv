{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to use lccv package, dont forget to execute:\n",
    "# export PYTHONPATH=/home/janvanrijn/projects/lccv (adapt to local directory)\n",
    "\n",
    "import lccv\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openmlid = 41161\n",
    "X, y = sklearn.datasets.fetch_openml(data_id=openmlid, return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running without Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lccv.lccv(sklearn.linear_model.LogisticRegression(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running With Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lccv.lccv(sklearn.linear_model.LogisticRegression(), X, y, timeout=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lccv.lccv(sklearn.tree.DecisionTreeClassifier(), X, y, r = 1.0, enforce_all_anchor_evaluations=True, timeout=500, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Recommendations on whether or not collect more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from lccv import lccv\n",
    "from evalutils import *\n",
    "\n",
    "def check_possible_improvement(learner, X, y):\n",
    "    n = X.shape[0]\n",
    "    target = int(0.9 * n)\n",
    "    half = int(target/2)\n",
    "    print(\"Conducting validation on \" + str(half) + \"/\" + str(target) + \" instances.\")\n",
    "    validation_score, mean_estimates, estimates, elm = lccv.lccv(learner(), X, y, r = 1.0, enforce_all_anchor_evaluations=True, target = half, timeout=500, verbose=False)\n",
    "    \n",
    "    prediction_on_full = elm.get_ipl_estimate_at_target(target)\n",
    "    expected_improvement = validation_score - prediction_on_full\n",
    "    print(\"Score at half size (\" + str(half) + \"):\", validation_score)\n",
    "    print(\"Estimated score on full data (\" + str(target) + \" instances):\", prediction_on_full)\n",
    "    print(\"This would be an improvement of:\", expected_improvement)\n",
    "    recommendation = expected_improvement >= 0.01\n",
    "    print(\"Recommending to double the number of instances:\", recommendation)\n",
    "    \n",
    "    # now computing the true performance there\n",
    "    print(\"Now computing the TRUE performance at the target.\")\n",
    "    for seed in range(10):\n",
    "        elm.compute_and_add_sample(target, seed=seed)\n",
    "    true_performance_at_target = np.mean(elm.get_values_at_anchor(target))\n",
    "    true_improvement_at_target = validation_score - true_performance_at_target\n",
    "    print(\"True performance at target:\", true_performance_at_target)\n",
    "    print(\"The true improvement is:\", true_improvement_at_target)\n",
    "    print(\"Recommendation was \" + (\"good\" if (recommendation and true_improvement_at_target >= 0.01 or not recommendation and true_improvement_at_target < 0.01) else \"bad\"))\n",
    "\n",
    "    \n",
    "learner = sklearn.tree.DecisionTreeClassifier\n",
    "print(\"Conducting recommendation analysis now only for \" + learner.__name__)\n",
    "\n",
    "print(\"\\n----------------- 1 -----------------\")\n",
    "print(\"Doing this on higgs. Here we *will* recognize saturation and the recommendation for more data will be good.\")\n",
    "openmlid = 23512\n",
    "X, y = get_dataset(openmlid)\n",
    "check_possible_improvement(learner, X, y)\n",
    "\n",
    "print(\"\\n----------------- 2 -----------------\")\n",
    "print(\"Doing this on Madelon will be overly optimistic, but the recommendation for more data would still be correct.\")\n",
    "openmlid = 1485\n",
    "X, y = get_dataset(openmlid)\n",
    "check_possible_improvement(learner, X, y)\n",
    "\n",
    "print(\"\\n----------------- 3 -----------------\")\n",
    "print(\"We are also good in recognizing it on wine-quality-white!\")\n",
    "openmlid = 40498\n",
    "X, y = get_dataset(openmlid)\n",
    "check_possible_improvement(learner, X, y)\n",
    "\n",
    "print(\"\\n----------------- 4 -----------------\")\n",
    "print(\"On amazon, it works also well!\")\n",
    "openmlid = 1457\n",
    "X, y = get_dataset(openmlid)\n",
    "check_possible_improvement(learner, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
